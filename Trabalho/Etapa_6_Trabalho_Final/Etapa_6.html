<!DOCTYPE html>
<html lang="pt">
<head>
<title>Etapa 6</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
* {
    box-sizing: border-box;
}

body {
  font-family: Arial, Helvetica, sans-serif;
}

header {
  background-color: #6a8d3c;
  padding: 10px;
  text-align: center;
  font-size: 35px;
  color: white;
}

section {
  display: -webkit-flex;
  display: flex;
}

nav {
  -webkit-flex: 1;
  -ms-flex: 1;
  flex: 1;
  background: #ccc;
  padding: 20px;
}

nav ul {
  list-style-type: none;
  padding: 0;
}

article {
  -webkit-flex: 3;
  -ms-flex: 3;
  flex: 3;
  background-color: #f1f1f1;
  padding: 12px;
}

footer {
  background-color: #708090;
  padding: 10px;
  text-align: center;
  color: white;
}

.code-box {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 0;
            border-radius: 5px;
            font-family: monospace;
            white-space: pre;
            width: 800px; 
            margin: 0 auto; 
            overflow-x: auto; 
}

figcaption {
    font-size: 14px;
    color: #555;
    margin-top: 5px;
}


@media (max-width: 600px) {
  section {
    -webkit-flex-direction: column;
    flex-direction: column;
  }
}
</style>
</head>
<body>

<header>
    <h1>ESZA019-17SA - Visão Computacional</h1>
    <h3>Trabalho - Etapa 6: Relatório Final</h3>
    <h5>Integrantes
    <br>Diego Aoyagi de Souza - RA: 11066516
    <br>Gabriel Gomes de Oliveira - RA: 11108214
    <br>Gustavo Cardoso Bezerra - RA: 11201822553</h5>
    <h6>Data de publicação: 30/08/2024</h6>
</header>

<section>  
  <article> <!-- Texto central que indica a introdução do laboratório em questão-->
    <h2><center>1.0 INTRODUÇÃO</center></h2>
    <p><justify>
        <b>1.1 Apresentação do Trabalho</b><br>
        O reconhecimento facial tem se tornado uma ferramenta essencial para a contagem de público em eventos, oferecendo precisão e eficiência superiores aos métodos tradicionais. Utilizando algoritmos da biblioteca OpenCV, como Haar Cascades, HOG e LBPH, é possível detectar e contar rostos em tempo real, além de analisar dados demográficos e melhorar a segurança e a gestão dos eventos. A tecnologia não só automatiza a contagem, reduzindo erros e custos, como também fornece insights valiosos sobre o perfil dos participantes. No entanto, sua implementação enfrenta desafios relacionados a condições ambientais variáveis e questões de privacidade, que devem ser cuidadosamente abordados para garantir uma aplicação ética e eficaz.
        <br><br>
        <b>1.2 Justificativa</b><br>
        A contagem precisa e eficiente de público em eventos é crucial para a gestão adequada e a segurança dos participantes, além de fornecer dados valiosos para análise de público e planejamento futuro. Métodos tradicionais, como contagem manual ou sensores de presença, muitas vezes falham em lidar com a escala e a complexidade dos eventos modernos, resultando em erros e ineficiências. O reconhecimento facial, apoiado por algoritmos avançados da biblioteca OpenCV, oferece uma solução tecnológica que não só automatiza e agiliza o processo de contagem, mas também melhora a precisão e a capacidade de análise em tempo real. Esse sistema pode identificar e contar participantes de maneira eficaz, mesmo em condições desafiadoras, e fornecer insights sobre o perfil demográfico do público. Além disso, a utilização do reconhecimento facial pode contribuir para um melhor controle de acesso e segurança, reduzindo filas e otimizando a experiência do usuário. Considerando a crescente demanda por tecnologias que aumentem a eficiência e a precisão em eventos, desenvolver um projeto baseado nessa tecnologia é altamente relevante e pode proporcionar benefícios significativos para a gestão de eventos e para a experiência dos participantes.
        <br><br>
        <b>1.3 Objetivo</b><br>
        Este projeto visa desenvolver um sistema de contagem de público para ambientes fechados, utilizando visão computacional para fornecer em tempo real a quantidade de pessoas presentes. A solução será implementada com o auxílio das bibliotecas OpenCV e a linguagem de programação Python, empregando algoritmos de reconhecimento facial para detectar e contabilizar os indivíduos no local. O objetivo é oferecer uma ferramenta eficiente para monitorar a ocupação de salas fechadas, melhorando a gestão do espaço e a segurança dos eventos.
    </justify></p>

    <br>
    <h2><center>2.0 METODOLOGIA</center></h2>
    <p><justify>
        Antes de iniciar o desenvolvimento do projeto, é essencial elaborar um planejamento detalhado que defina claramente os temas a serem abordados, as metodologias a serem utilizadas e os objetivos a serem alcançados. Esse planejamento servirá como base para a pesquisa de referências e a identificação de possíveis melhorias a serem implementadas. Para isso, é necessário realizar uma pesquisa aprofundada em diversas plataformas, a fim de reunir informações relevantes e fundamentar a implementação e análise dos resultados de maneira eficaz.
        <br><br>
        <b>2.1 Referencial Teórico</b><br>
        O referencial teórico é uma seção essencial de projetos de pesquisa ou desenvolvimento, fornecendo a base de teorias, conceitos e estudos anteriores relacionados ao tema. Ele contextualiza o projeto dentro do conhecimento atual, justifica a relevância e ajuda a identificar lacunas e oportunidades para novas investigações. Além disso, orienta a escolha da metodologia, fundamenta as hipóteses e assegura que o trabalho mantenha foco e coerência. Serve também para comparar os resultados obtidos com o conhecimento existente, fortalecendo a credibilidade do projeto e assegurando que ele contribua de maneira significativa para o campo.
        <br><br>
        <b>2.2 Desenvolvimento</b><br>
        A fase de desenvolvimento do projeto envolve a aplicação prática dos conhecimentos e conceitos previamente pesquisados e discutidos. Após a definição do referencial teórico, que fornece uma base sólida e um contexto para o projeto, a fase de desenvolvimento começa com a concretização das ideias e estratégias delineadas. Nessa etapa, os conceitos e teorias são traduzidos em práticas e ações específicas, incluindo o design e a implementação de metodologias, técnicas e ferramentas. A equipe trabalha para construir, testar e ajustar as soluções propostas, garantindo que estejam alinhadas com os objetivos estabelecidos e com o conhecimento pré-existente. Durante essa fase, é essencial monitorar e documentar o progresso para garantir que o projeto avance de acordo com o planejamento teórico e esteja preparado para a análise e interpretação dos resultados obtidos. Em resumo, a fase de desenvolvimento é onde a teoria se torna prática, permitindo a realização concreta dos objetivos do projeto e a verificação da validade das hipóteses formuladas.
        <br><br>
        <b>2.3 Testes</b><br>
        A fase de testes em um projeto é crucial para validar a eficácia e a robustez da solução desenvolvida, ainda mais quando envolve algoritmos de identificação de pessoas. Durante essa fase, é essencial realizar uma série de testes para avaliar o desempenho do algoritmo em diferentes condições, como variações na iluminação, ângulos de visão e densidade de público. Testar amplamente permite identificar e corrigir falhas, ajustar parâmetros e melhorar a precisão do reconhecimento facial.
        <br><br>
        <b>2.4 Análise e Interpretação dos Resultados</b><br>
        A análise dos resultados dos testes fornece insights valiosos sobre as limitações do algoritmo e áreas de aprimoramento, possibilitando ajustes que aumentem a eficiência e a precisão do sistema. Assim, a fase de testes não só assegura que o sistema atenda aos requisitos estabelecidos, mas também contribui para a evolução contínua do projeto, resultando em uma solução mais robusta e eficaz.
    </justify></p>

    <br>
    <h2><center>3.0 REFERENCIAL TEÓRICO</center></h2>
    <p><justify>
        <b>3.1 Reconhecimento Facial</b><br>
        O reconhecimento facial é uma tecnologia que permite identificar ou verificar indivíduos com base em características faciais. Essa tecnologia é importante por sua capacidade de oferecer uma forma eficiente e não invasiva de autenticação e identificação em uma variedade de contextos, desde segurança e controle de acesso até personalização de serviços.
        <br><br>
        A sua utilização é ampla e abrange áreas como segurança pública, onde pode ajudar na identificação de pessoas em vídeos de vigilância; sistemas de pagamento e autenticação, onde é usada para desbloquear dispositivos ou autorizar transações; e até mesmo em marketing, para personalizar a experiência do usuário com base nas características faciais detectadas.
        <br><br>
        O processo de reconhecimento facial geralmente começa com a captura de uma imagem ou vídeo do rosto de um indivíduo. Em seguida, o sistema analisa essa imagem para identificar características faciais distintivas e compará-las com um banco de dados de imagens conhecidas. A identificação é feita com base na correspondência dessas características, permitindo determinar a identidade da pessoa. Essa tecnologia pode operar em tempo real e é cada vez mais integrada em dispositivos móveis, sistemas de segurança e plataformas online, tornando-se uma ferramenta valiosa para diversos aplicativos modernos com a implementação aliada ao OpenCV.
        <br><br>
        <b>3.2 Biblioteca OpenCV</b><br>
        OpenCV é uma biblioteca de código aberto que fornece uma ampla gama de ferramentas e algoritmos para processamento de imagem e visão computacional. Ela facilita a realização de tarefas complexas como detecção de objetos, reconhecimento facial e análise de vídeo, permitindo que desenvolvedores criem aplicações avançadas com relativa facilidade.
        <br><br>
        A integração do OpenCV com Python é especialmente poderosa e popular devido à simplicidade e flexibilidade do Python. A biblioteca OpenCV-Python oferece uma interface que permite usar as funcionalidades do OpenCV diretamente na linguagem Python, combinando a robustez dos algoritmos de visão computacional com a legibilidade e a facilidade de uso do Python. Isso facilita o desenvolvimento e a implementação de soluções de visão computacional, tornando a tecnologia mais acessível para pesquisadores, engenheiros e desenvolvedores.
        <br><br>
        <div id="ladoalado">
          <div style="display: flex; justify-content: space-around; margin-bottom: 10px;">
              <img src="imagem_1.jpg" style="width: 50%; height: auto;">
          </div>
        </div>
        <center><figcaption>Disponível em: <a href="https://medium.com/@sasasulakshi/opencv-installation-and-getting-started-with-image-processing-acec2ba5343d" target="_blank">https://medium.com/@sasasulakshi/opencv-installation-and-getting-started-with-image-processing-acec2ba5343d</a></figcaption><p></center>
        <br><br>
        <b>3.3 Tipos de Reconhecimento</b><br>
        Utilizando OpenCV, existem vários tipos de reconhecimento de pessoas que podem ser realizados. Aqui estão os principais:
        <br><br>
        <b>3.3.1. Reconhecimento Facial:</b><br>
        É a identificação de indivíduos com base nas características faciais. O OpenCV oferece algoritmos para detectar e reconhecer rostos em imagens e vídeos. Isso pode incluir técnicas como reconhecimento facial baseado em características (por exemplo, Eigenfaces e Fisherfaces) ou métodos mais modernos usando redes neurais profundas.
        <br><br>
        <b>3.3.2. Reconhecimento de Ações:</b><br>
        Este tipo de reconhecimento envolve identificar e interpretar ações ou comportamentos de uma pessoa em um vídeo. Usando o OpenCV, é possível analisar a movimentação e o padrão de ações para detectar atividades específicas, como andar, correr ou gesticular.
        <br><br>
        <b>3.3.3. Reconhecimento de Pessoas em Vídeo:</b><br>
        Em vídeos, o OpenCV pode ser usado para rastrear e identificar indivíduos ao longo do tempo, analisando a sequência de imagens para manter a identificação consistente à medida que a pessoa se move e muda de posição.
        <br><br>
        <b>3.3.4. Detecção de Pontos Faciais:</b><br>
        OpenCV pode identificar pontos específicos no rosto, como olhos, nariz e boca. Esses pontos são usados para alinhar e normalizar rostos antes de realizar o reconhecimento facial.
        <br><br>
        <b>3.3.5. Detecção de Emoções:</b><br>
        Utilizando técnicas de visão computacional, o OpenCV pode ser combinado com algoritmos adicionais para detectar e classificar emoções com base nas expressões faciais.
        <br><br>
        <b>3.3.6. Identificação de Rosto em Grupo:</b><br>
        O OpenCV pode distinguir rostos individuais em uma multidão ou em imagens com várias pessoas, ajudando a identificar e contar o número de pessoas presentes.
        <br><br>
        Cada um desses métodos pode ser implementado usando as ferramentas e algoritmos fornecidos pelo OpenCV, muitas vezes em combinação com outras bibliotecas e técnicas de aprendizado de máquina para melhorar a precisão e a eficácia dos sistemas de reconhecimento de pessoas.
        <br><br>
        <br><br>
        <div id="ladoalado">
          <div style="display: flex; justify-content: space-around; margin-bottom: 10px;">
              <img src="imagem_2.jpg" style="width: 50%; height: auto;">
          </div>
        </div>
        <center><figcaption>Disponível em: <a href="https://pt.linkedin.com/pulse/opencv-1-usando-com-cpython-eymard-silva" target="_blank">https://pt.linkedin.com/pulse/opencv-1-usando-com-cpython-eymard-silva</a></figcaption><p></center>
        <br><br>
        <b>3.4 Técnicas de Reconhecimento</b><br>
        Os algoritmos de reconhecimento facial no OpenCV utilizam uma variedade de técnicas e métodos para identificar e distinguir rostos. Aqui estão algumas das principais técnicas empregadas:
        <br><br>
        <b>3.4.1. Haar Cascades:</b><br>
        Esta técnica usa classificadores em cascata baseados em características de Haar, que são formas simples, como bordas e linhas, para detectar rostos em imagens. O classificador é treinado com uma grande quantidade de imagens positivas (com rostos) e negativas (sem rostos) para aprender a identificar padrões faciais.
        <br><br>
        <b>3.4.2. Histograma de Gradientes Orientados (HOG):</b><br>
        Usado principalmente para a detecção de objetos, o método HOG analisa a orientação dos gradientes em diferentes regiões da imagem. É eficaz para detectar rostos e outros objetos com características distintas em imagens.
        <br><br>
        <b>3.4.3. Local Binary Patterns (LBP):</b><br>
        LBP é uma técnica que descreve a textura de uma imagem com base nas informações binárias das regiões ao redor de cada pixel. É usado para a detecção e reconhecimento facial, especialmente para identificar padrões faciais característicos.
        <br><br>
        <b>3.4.4. Eigenfaces:</b><br>
        Esta técnica de reconhecimento facial usa análise de componentes principais (PCA) para reduzir a dimensionalidade dos dados faciais e identificar padrões. Eigenfaces transforma as imagens de rosto em um conjunto de características principais que são usadas para comparar e reconhecer rostos.
        <br><br>
        <b>3.4.5. Fisherfaces:</b><br>
        Baseado na Análise Discriminante Linear (LDA), Fisherfaces melhora o desempenho do reconhecimento facial ao considerar a separação entre diferentes classes de rostos, em vez de apenas a variação total como no PCA. Isso torna o reconhecimento mais robusto a variações de iluminação e expressões faciais.
        <br><br>
        <b>3.4.6. Reconhecimento Facial com Redes Neurais:</b><br>
        O OpenCV pode ser integrado com bibliotecas de aprendizado profundo, como TensorFlow e PyTorch, para usar redes neurais convolucionais (CNNs) para reconhecimento facial. Essas redes são treinadas com grandes conjuntos de dados para aprender representações faciais complexas e fazer reconhecimento mais preciso.
        <br><br>
        <b>3.4.7. Face Landmark Detection:</b><br>
        Este método identifica pontos de referência em um rosto, como os olhos, nariz e boca. Esses pontos são usados para alinhar o rosto e melhorar a precisão do reconhecimento facial, especialmente em condições de iluminação variáveis ou ângulos diferentes.
        <br><br>
        <b>3.4.8. LBPH (Local Binary Patterns Histograms):</b><br>
        Uma variação do método LBP, LBPH combina a descrição de textura com histogramas para capturar e comparar características faciais. É eficaz em reconhecer rostos em diferentes condições de iluminação e expressões.
        <br><br>
        Cada uma dessas técnicas possui suas próprias vantagens e limitações, e a escolha do método pode depender dos requisitos específicos do aplicativo, como a precisão necessária, a velocidade de processamento e as condições de operação. O OpenCV oferece implementações desses métodos, permitindo aos desenvolvedores construir e adaptar sistemas de reconhecimento facial de acordo com suas necessidades.
        <br><br>
        <b>3.5 Fatores que Influenciam o Reconhecimento</b><br>
        O reconhecimento facial pode ser significativamente afetado por uma variedade de fatores que impactam a qualidade e a precisão do processo. A posição da câmera, por exemplo, desempenha um papel crucial na eficácia do reconhecimento. Se a câmera estiver mal posicionada ou inclinada, pode resultar em uma imagem distorcida ou em ângulo, dificultando a detecção e a identificação precisa do rosto. Além disso, a distância entre a câmera e a pessoa pode influenciar a qualidade da imagem capturada. Se a pessoa estiver muito longe, o rosto pode aparecer pequeno e detalhado de forma inadequada, enquanto se estiver muito perto, pode haver distorções ou cortes na imagem.
        <br><br>
        Objetos que cobrem parcialmente o rosto, como óculos escuros, chapéus ou mesmo outros indivíduos em uma multidão, podem obstruir características faciais importantes e dificultar a identificação. A presença de sombras, iluminação inadequada ou reflexos também pode afetar negativamente a qualidade da imagem e a precisão do reconhecimento. Imagens mal iluminadas podem criar áreas escuras ou brilhantes que obscurecem características faciais cruciais, enquanto uma iluminação muito forte pode resultar em sombras duras ou brilho excessivo.
        <br><br>
        A definição da imagem é outro fator determinante. Imagens de baixa resolução podem não capturar detalhes faciais suficientes, o que dificulta a extração de características precisas para reconhecimento. A resolução alta é importante para garantir que todos os detalhes faciais sejam capturados e analisados com precisão. Além disso, o ambiente ao redor, como o fundo da imagem e a presença de múltiplos rostos, também pode afetar a capacidade do sistema de reconhecer corretamente uma pessoa.
        <br><br>
        Esses fatores juntos influenciam a eficácia do sistema de reconhecimento facial, e ajustes na configuração da câmera, na iluminação e na resolução da imagem são frequentemente necessários para otimizar o desempenho do sistema e garantir a precisão do reconhecimento.
        <br><br>
        Com isso, o uso de ferramentas como YOLO (You Only Look Once) ajudam a maximizar os acertos dos reconhecimentos e evitar alguns dos fatores citados anteriormente.
        <br><br>
        <b>3.6 YOLO</b><br>
        O YOLO, é uma técnica revolucionária para detecção de objetos em imagens e vídeos, desenvolvida para proporcionar uma solução rápida e eficiente para identificar e localizar objetos em tempo real. Sua principal inovação está na sua abordagem única de processar a imagem. Em vez de dividir o processo de detecção em múltiplas etapas, como muitos métodos tradicionais, o YOLO realiza todas as previsões em uma única passagem pela rede neural. Isso resulta em uma grande eficiência, permitindo que os objetos sejam detectados de forma rápida e precisa.
        <br><br>
        A aplicação do YOLO em visão computacional envolve o uso de redes neurais convolucionais (CNNs) para analisar imagens e identificar objetos com alta precisão. A rede neural é treinada para reconhecer uma variedade de objetos, como pessoas, veículos, animais e muito mais. Para isso, o YOLO divide a imagem em uma grade e cada célula dessa grade é responsável por prever a presença de objetos e suas respectivas localizações. Isso inclui a identificação das caixas delimitadoras, que são as regiões onde os objetos são detectados, e a classificação desses objetos em diferentes categorias.
        <br><br>
        Quando aplicado à detecção de pessoas, o YOLO pode identificar indivíduos em uma cena e localizar sua posição exata com base em caixas delimitadoras. Essa capacidade é particularmente útil em várias áreas, como segurança e vigilância, onde a detecção em tempo real de pessoas é crucial. Em sistemas de vigilância, por exemplo, o YOLO pode analisar fluxos de vídeo e destacar automaticamente a presença de pessoas, facilitando o monitoramento e a análise de atividades em tempo real.
        <br><br>
        <b>3.7 Relação OpenCV e YOLO</b><br>
        A integração entre YOLO e OpenCV geralmente ocorre da seguinte maneira: Primeiro, OpenCV é utilizado para carregar e preparar as imagens ou frames de vídeo. Isso pode incluir operações como redimensionamento, normalização e conversão de formatos, que são etapas necessárias para garantir que os dados estejam no formato adequado para o modelo YOLO. Após essa preparação, o YOLO é aplicado para detectar objetos. O modelo YOLO processa as imagens e fornece as previsões sobre a localização e a classe dos objetos detectados.
        <br><br>
        Uma vez que YOLO gera as previsões, OpenCV entra novamente em ação para realizar o pós-processamento. Isso inclui a visualização dos resultados, como desenhar caixas delimitadoras ao redor dos objetos detectados e adicionar rótulos com as classes dos objetos. OpenCV também pode ser usado para exibir as imagens ou vídeos processados em uma interface gráfica, permitindo o salvamento dos resultados, ou até mesmo integrar a detecção em sistemas de vigilância em tempo real.
        <br><br>
        <div id="ladoalado">
          <div style="display: flex; justify-content: space-around; margin-bottom: 10px;">
              <img src="imagem_3.jpg" style="width: 50%; height: auto;">
          </div>
        </div>
        <center><figcaption>Disponível em: <a href="https://dsbyprateekg.blogspot.com/2020/08/how-to-use-opencv-python-with-darknets.html" target="_blank">https://dsbyprateekg.blogspot.com/2020/08/how-to-use-opencv-python-with-darknets.html</a></figcaption><p></center>
    </justify></p>

    <br>
    <h2><center>4.0 DESENVOLVIMENTO</center></h2>
    <p><justify>
        Com base no referencial teórico e nos modelos de sucesso identificados, nosso objetivo é iniciar com aplicações simples e, gradualmente, sofisticar a solução ao longo do tempo. No início, a definição do local e a posição da câmera são cruciais para alcançar os objetivos do projeto.
        <br><br>
        Para a implementação, optamos por um ambiente fechado, como uma sala de aula, onde posicionaremos uma câmera próxima à entrada, voltada para o fundo da sala. O objetivo é realizar o reconhecimento de pessoas utilizando algoritmos de reconhecimento facial, permitindo quantificar o número de indivíduos presentes. Vale ressaltar que o foco do projeto não é identificar cada pessoa individualmente, mas sim distinguir se o objeto identificado é uma pessoa ou não.
        <br><br>
        <b>4.1 Primeiros Testes</b><br>
        Primeiramente realizamos testes utilizando o Haar Cascades, porém verificamos que ele apresentava um índice de confiabilidade baixo, identificando objetos como computadores como sendo pessoas, desta forma, optamos por utilizar outro modelo de detecção de pessoas. Dentre os testes, o Yolo V8 foi o modelo que apresentou a melhor relação praticidade e confiabilidade, nos permitindo regular o nível mínimo do índice de confiabilidade de detecção de pessoas. Desta forma, o Yolo V8n foi o escolhido para utilização em nosso projeto.
        <br><br>
        <b>4.2 Análise dos resultado iniciais</b><br>
        No primeiro teste realizado, observamos que o algoritmo conseguiu reconhecer de forma muito assertiva o que são pessoas nas cenas de vídeos de teste e em vídeos capturados pela webcam utilizando o índice de confiabilidade de 60% da classe de pessoas.
        <div id="ladoalado">
          <div style="display: flex; justify-content: space-around; margin-bottom: 10px;">
              <img src="imagem_4.png" style="width: 50%; height: auto;">
          </div>
        </div>
        <center><figcaption>Captura de tela do funcionamento do projeto detectando pessoas.</figcaption><p></center>
        <div id="ladoalado">
          <div style="display: flex; justify-content: space-around; margin-bottom: 10px;">
              <img src="imagem_5.png" style="width: 50%; height: auto;">
          </div>
        </div>
        <center><figcaption>Captura de tela do funcionamento do projeto detectando pessoas na sala.</figcaption><p></center>
        <br><br>
        <b>4.3 Complementos</b><br>
        Para complementar a usabilidade do projeto e para que ele sirva como modelo de ensino sobre visão computacional, adicionamos a possibilidade do usuário escolher o índice de detecção de pessoas, a quantidade de frames que o script utiliza para calcular a média de pessoas e a classe de objetos para identificar pessoas e celular.
        <br><br>
        <b>4.3 Requisitos</b><br>
        Para executar o projeto, é necessário ter instalado o python com a versão mínima 3.8 e as bibliotecas a seguir: opencv-python evzone numpy torch torchvision ultralytics tk
        <br>
        Com o python e as bibliotecas instaladas, basta executar o comando a seguir que o script comece a funcionar: python contagem_pessoas.py
    </justify></p>
    <br>
    <h2><center>5.0 Resultados</center></h2>
    <p><justify>
      Com o projeto pronto, demonstramos o seu funcionamento para os outros grupos da sala para verificarem a usabilidade e para explicar como a identificação e cálculo de quantidade de pessoas na cena estava sendo feito. Como pode ser visto a seguir, temos um aluno testando o projeto.

      <p><center><video src="video_2.mp4" style="width: 50%; height: auto;" controls autoplay loop></video></center></p>
      <br>
      A seguir, temos outro teste realizado em sala de aula demonstrando o funcionamento do projeto.
      <p><center><video src="video_1.mp4" style="width: 50%; height: auto;" controls autoplay loop></video></center></p>
    </justify></p>

    <h2><center>6.0 Conclusão</center></h2>
    <p><justify>
      O desenvolvimento do sistema de reconhecimento facial para contagem de público em ambientes fechados demonstrou a aplicabilidade e a eficiência das tecnologias de visão computacional na gestão de eventos e segurança. A implementação de algoritmos avançados como Haar Cascades e YOLOv8, integrados com a biblioteca OpenCV, possibilitou a criação de uma solução robusta e escalável, capaz de identificar e contabilizar indivíduos em tempo real, mesmo em condições desafiadoras.

      Durante as fases de testes e ajustes, observamos a importância de selecionar algoritmos apropriados e de configurar corretamente parâmetros como o índice de confiabilidade, o que impactou diretamente a precisão e a eficiência do sistema. A escolha do YOLOv8, em particular, mostrou-se acertada, pois ofereceu um equilíbrio ideal entre praticidade e confiabilidade, superando limitações observadas em métodos anteriores, como o Haar Cascades.
      
      A análise dos resultados iniciais confirmou que o sistema é capaz de realizar detecções com alta precisão, com uma taxa de acerto significativa em diferentes cenários de teste. Além disso, a inclusão de funcionalidades adicionais, como a personalização do índice de detecção e a escolha de classes de objetos, ampliou a usabilidade do sistema, tornando-o uma ferramenta versátil para aplicações educacionais e práticas em visão computacional.
      
      Em resumo, o projeto atingiu seus objetivos principais, fornecendo uma solução eficiente para a contagem de público, que pode ser aplicada em diversos contextos de monitoramento e segurança. Através de ajustes contínuos e melhorias baseadas nos testes realizados, o sistema está preparado para contribuir significativamente para a gestão de eventos e a segurança em ambientes controlados, destacando-se como um exemplo bem-sucedido da aplicação de tecnologias de visão computacional no mundo real.
    </justify></p>
    <h2><center>7.0 Referências</center></h2>
    <p><justify><center>
        Tutorial OpenCV e Python:
        <a href="https://docs.opencv.org/master/d6/d00/tutorial_py_root.html" target="_blank">https://docs.opencv.org/master/d6/d00/tutorial_py_root.html</a>
        <br>Getting Started with Images:
        <a href="https://docs.opencv.org/4.x/db/deb/tutorial_display_image.html" target="_blank">https://docs.opencv.org/4.x/db/deb/tutorial_display_image.html</a>
        <br>Getting Started with Videos:
        <a href="https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html" target="_blank">https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html</a>
        <br>Curso OpenCV Python - Português:
        <a href="https://www.youtube.com/playlist?list=PLsyobOqUhkthjvmA_s7tTjb7V2EiwYYGC" target="_blank">https://www.youtube.com/playlist?list=PLsyobOqUhkthjvmA_s7tTjb7V2EiwYYGC</a>
        <br>Geometria da formação de imagens:
        <a href="https://learnopencv.com/geometry-of-image-formation" target="_blank">https://learnopencv.com/geometry-of-image-formation</a>
        <br>Teoria da Calibração de Câmera com OpenCV:
        <a href="https://learnopencv.com/camera-calibration-using-opencv" target="_blank">https://learnopencv.com/camera-calibration-using-opencv</a>
        <br><br>
        [1] Richard Hartley and Andrew Zisserman. 2003. Multiple View Geometry in Computer Vision (2nd. ed.). Cambridge University Press, USA.
        <br>[2] D. Scharstein, H. Hirschmüller, Y. Kitajima, G. Krathwohl, N. Nesic, X. Wang, and P. Westling. High-resolution stereo datasets with subpixel-accurate ground truth. In German Conference on Pattern Recognition (GCPR 2014), Münster, Germany, September 2014.
        <br>[3] H. Hirschmuller, “Stereo Processing by Semiglobal Matching and Mutual Information,” in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, no. 2, pp. 328-341, Feb. 2008, doi: 10.1109/TPAMI.2007.1166.
    </center></justify></p>

  </article>
</section>

<footer>
  <p>2º Quadrimestre 2024</p>
</footer>

</body>
</html>
